# MSDS 6120: Capstone A

# Authors: Anand Rajan, Benjamin Wilke, and Tej Tenmattam

Identifying Complex Metadata Relationships to Objects using Natural Language Processing and Image Classification.

Abstract: In this paper we present the integration of natural language processing and computer vision to identify complex relationships be- tween objects in images. Computer vision has mostly been concerned with fairly low-level tasks, such as grouping contours, edges, and ba- sic shapes in images to identify objects. Natural language processing is a much wider domain and includes tasks such as identifying syntax, seman- tics, and relations between words. We seek to combine these practices to express higher order relationships than simply identifying objects in an image. If a picture is worth a thousand words than our goal is to generate these words to not only understand the objects in an image, but interactions and activities between the objects. Our work will begin by mining keywords, captions, and other available descriptive narratives from images using natural language processing techniques. We will cre- ate a multimodal neural network combining convolutional and recurrent architectures to create a model that can maximize the likelihood of word combinations given a training image. Our research will also demonstrate how these encoder/decoder architectures can learn from only relevant interactions that occur in an image. Finally, we will test, document, and iterate over the results to maximize our potential for uncovering higher order classifications and provide quantitative and qualitative measure- ment of effectiveness.
